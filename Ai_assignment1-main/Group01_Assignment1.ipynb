{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Assignment 1: KNN Classification from Scratch\n",
    "## Group: Group01_Assignment1\n",
    "\n",
    "This notebook implements K-Nearest Neighbors (KNN) classification from scratch for:\n",
    "1. **Task 1**: Binary Classification on Breast Cancer Dataset\n",
    "2. **Task 2**: Multi-class Classification on CIFAR-10 Dataset\n",
    "\n",
    "**Note**: No sklearn or pytorch functions are used for the models - everything is implemented from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "import tarfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Distance Functions Implementation (From Scratch)\n",
    "We implement all 5 distance metrics from scratch without using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceMetrics:\n",
    "    \"\"\"Class containing all distance metric implementations from scratch\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean_distance(x1, x2):\n",
    "        \"\"\"Euclidean Distance: sqrt(sum((x1 - x2)^2))\"\"\"\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def manhattan_distance(x1, x2):\n",
    "        \"\"\"Manhattan Distance: sum(|x1 - x2|)\"\"\"\n",
    "        return np.sum(np.abs(x1 - x2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def minkowski_distance(x1, x2, p=3):\n",
    "        \"\"\"Minkowski Distance: (sum(|x1 - x2|^p))^(1/p)\"\"\"\n",
    "        return np.power(np.sum(np.power(np.abs(x1 - x2), p)), 1/p)\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_similarity(x1, x2):\n",
    "        \"\"\"Cosine Similarity: 1 - (x1.x2)/(||x1|| * ||x2||)\n",
    "        Returns distance (1 - similarity) so that smaller values mean more similar\"\"\"\n",
    "        dot_product = np.dot(x1, x2)\n",
    "        norm_x1 = np.sqrt(np.sum(x1 ** 2))\n",
    "        norm_x2 = np.sqrt(np.sum(x2 ** 2))\n",
    "        if norm_x1 == 0 or norm_x2 == 0:\n",
    "            return 1.0\n",
    "        similarity = dot_product / (norm_x1 * norm_x2)\n",
    "        return 1 - similarity  # Convert to distance\n",
    "    \n",
    "    @staticmethod\n",
    "    def hamming_distance(x1, x2):\n",
    "        \"\"\"Hamming Distance: proportion of differing components\n",
    "        For continuous data, we threshold to create binary features\"\"\"\n",
    "        # For continuous features, we use a threshold-based approach\n",
    "        threshold = 0.5\n",
    "        x1_binary = (x1 > threshold).astype(int)\n",
    "        x2_binary = (x2 > threshold).astype(int)\n",
    "        return np.sum(x1_binary != x2_binary) / len(x1)\n",
    "\n",
    "print(\"Distance metrics implemented successfully!\")\n",
    "print(\"\\nFormulas:\")\n",
    "print(\"1. Euclidean: d(x,y) = sqrt(Σ(xi - yi)²)\")\n",
    "print(\"2. Manhattan: d(x,y) = Σ|xi - yi|\")\n",
    "print(\"3. Minkowski: d(x,y) = (Σ|xi - yi|^p)^(1/p), p=3\")\n",
    "print(\"4. Cosine: d(x,y) = 1 - (x·y)/(||x||·||y||)\")\n",
    "print(\"5. Hamming: d(x,y) = (1/n) × Σ(xi ≠ yi)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: KNN Classifier Implementation (From Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    \"\"\"K-Nearest Neighbors Classifier implemented from scratch\"\"\"\n",
    "    \n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        \"\"\"\n",
    "        Initialize KNN Classifier\n",
    "        \n",
    "        Parameters:\n",
    "        - k: Number of neighbors\n",
    "        - distance_metric: One of 'euclidean', 'manhattan', 'minkowski', 'cosine', 'hamming'\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "        # Map distance metric names to functions\n",
    "        self.distance_functions = {\n",
    "            'euclidean': DistanceMetrics.euclidean_distance,\n",
    "            'manhattan': DistanceMetrics.manhattan_distance,\n",
    "            'minkowski': DistanceMetrics.minkowski_distance,\n",
    "            'cosine': DistanceMetrics.cosine_similarity,\n",
    "            'hamming': DistanceMetrics.hamming_distance\n",
    "        }\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Store training data (lazy learning)\"\"\"\n",
    "        self.X_train = np.array(X_train)\n",
    "        self.y_train = np.array(y_train)\n",
    "        return self\n",
    "    \n",
    "    def _compute_distance(self, x1, x2):\n",
    "        \"\"\"Compute distance between two points using the specified metric\"\"\"\n",
    "        distance_func = self.distance_functions[self.distance_metric]\n",
    "        return distance_func(x1, x2)\n",
    "    \n",
    "    def _predict_single(self, x):\n",
    "        \"\"\"Predict the class for a single sample\"\"\"\n",
    "        # Calculate distances from x to all training samples\n",
    "        distances = [self._compute_distance(x, x_train) for x_train in self.X_train]\n",
    "        \n",
    "        # Get indices of k nearest neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # Get the labels of k nearest neighbors\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        \n",
    "        # Return the most common class label (majority voting)\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict classes for all test samples\"\"\"\n",
    "        X_test = np.array(X_test)\n",
    "        predictions = [self._predict_single(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "        return np.mean(y_pred == y_test)\n",
    "\n",
    "print(\"KNN Classifier implemented successfully!\")\n",
    "print(\"\\nAlgorithm Steps:\")\n",
    "print(\"1. Store training data (fit)\")\n",
    "print(\"2. For each test sample:\")\n",
    "print(\"   a. Calculate distance to all training samples\")\n",
    "print(\"   b. Find K nearest neighbors\")\n",
    "print(\"   c. Majority voting to determine class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Evaluation Metrics Implementation (From Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics:\n",
    "    \"\"\"Evaluation metrics implemented from scratch\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def confusion_matrix(y_true, y_pred, labels=None):\n",
    "        \"\"\"Create confusion matrix\"\"\"\n",
    "        if labels is None:\n",
    "            labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "        \n",
    "        n_labels = len(labels)\n",
    "        label_to_idx = {label: idx for idx, label in enumerate(labels)}\n",
    "        \n",
    "        cm = np.zeros((n_labels, n_labels), dtype=int)\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            cm[label_to_idx[true]][label_to_idx[pred]] += 1\n",
    "        \n",
    "        return cm, labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall(y_true, y_pred, labels=None):\n",
    "        \"\"\"Calculate precision and recall for each class\"\"\"\n",
    "        cm, labels = EvaluationMetrics.confusion_matrix(y_true, y_pred, labels)\n",
    "        \n",
    "        precisions = {}\n",
    "        recalls = {}\n",
    "        \n",
    "        for idx, label in enumerate(labels):\n",
    "            # True Positives\n",
    "            tp = cm[idx][idx]\n",
    "            # False Positives (column sum - TP)\n",
    "            fp = np.sum(cm[:, idx]) - tp\n",
    "            # False Negatives (row sum - TP)\n",
    "            fn = np.sum(cm[idx, :]) - tp\n",
    "            \n",
    "            # Precision = TP / (TP + FP)\n",
    "            precisions[label] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            # Recall = TP / (TP + FN)\n",
    "            recalls[label] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        \n",
    "        return precisions, recalls\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_true, y_pred):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        return np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_classification_report(y_true, y_pred, labels=None):\n",
    "        \"\"\"Print a classification report\"\"\"\n",
    "        cm, labels = EvaluationMetrics.confusion_matrix(y_true, y_pred, labels)\n",
    "        precisions, recalls = EvaluationMetrics.precision_recall(y_true, y_pred, labels)\n",
    "        acc = EvaluationMetrics.accuracy(y_true, y_pred)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CLASSIFICATION REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(f\"{'Class':<15} {'Precision':<12} {'Recall':<12}\")\n",
    "        print(\"-\"*40)\n",
    "        for label in labels:\n",
    "            print(f\"{str(label):<15} {precisions[label]:<12.4f} {recalls[label]:<12.4f}\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        # Macro averages\n",
    "        macro_precision = np.mean(list(precisions.values()))\n",
    "        macro_recall = np.mean(list(recalls.values()))\n",
    "        print(f\"{'Macro Avg':<15} {macro_precision:<12.4f} {macro_recall:<12.4f}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return cm, precisions, recalls, acc\n",
    "\n",
    "print(\"Evaluation metrics implemented successfully!\")\n",
    "print(\"\\nMetrics:\")\n",
    "print(\"- Precision = TP / (TP + FP)\")\n",
    "print(\"- Recall = TP / (TP + FN)\")\n",
    "print(\"- Accuracy = Correct Predictions / Total Predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 1: Binary Classification on Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')  # Update path as needed\n",
    "\n",
    "# Display basic info\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "df_clean = df.drop(columns=['id'], errors='ignore')\n",
    "df_clean = df_clean.loc[:, ~df_clean.columns.str.contains('^Unnamed')]\n",
    "df_clean = df_clean.dropna(axis=1, how='all')\n",
    "\n",
    "print(\"Missing values:\", df_clean.isnull().sum().sum())\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df_clean['diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_clean.drop(columns=['diagnosis']).values\n",
    "y = df_clean['diagnosis'].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features (Min-Max Scaling) - implemented from scratch\n",
    "def min_max_normalize(X):\n",
    "    \"\"\"Min-Max normalization implemented from scratch\"\"\"\n",
    "    X_min = np.min(X, axis=0)\n",
    "    X_max = np.max(X, axis=0)\n",
    "    range_val = X_max - X_min\n",
    "    range_val[range_val == 0] = 1  # Avoid division by zero\n",
    "    return (X - X_min) / range_val\n",
    "\n",
    "X_normalized = min_max_normalize(X)\n",
    "print(\"Features normalized using Min-Max scaling\")\n",
    "print(f\"Min: {X_normalized.min():.4f}, Max: {X_normalized.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split (80-20) - implemented from scratch\n",
    "def train_test_split_scratch(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"Train-test split implemented from scratch\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = len(X)\n",
    "    n_test = int(n_samples * test_size)\n",
    "    \n",
    "    indices = np.random.permutation(n_samples)\n",
    "    test_indices = indices[:n_test]\n",
    "    train_indices = indices[n_test:]\n",
    "    \n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_scratch(X_normalized, y, test_size=0.2)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples (80%)\")\n",
    "print(f\"Test set: {len(X_test)} samples (20%)\")\n",
    "print(f\"\\nTraining class distribution: M={np.sum(y_train=='M')}, B={np.sum(y_train=='B')}\")\n",
    "print(f\"Test class distribution: M={np.sum(y_test=='M')}, B={np.sum(y_test=='B')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Experiment with Different K Values and Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "k_values = [3, 4, 9, 20, 47]\n",
    "distance_metrics = ['euclidean', 'manhattan', 'minkowski', 'cosine', 'hamming']\n",
    "\n",
    "# Store results\n",
    "results = {metric: [] for metric in distance_metrics}\n",
    "\n",
    "print(\"Running experiments...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for metric in distance_metrics:\n",
    "    print(f\"\\nDistance Metric: {metric.upper()}\")\n",
    "    print(\"-\"*40)\n",
    "    for k in k_values:\n",
    "        knn = KNNClassifier(k=k, distance_metric=metric)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        accuracy = EvaluationMetrics.accuracy(y_test, y_pred)\n",
    "        results[metric].append(accuracy)\n",
    "        print(f\"  K={k:2d}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Experiments completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Results Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results, index=k_values)\n",
    "results_df.index.name = 'K Value'\n",
    "results_df.columns = [m.capitalize() for m in distance_metrics]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK 1: ACCURACY RESULTS TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string())\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best configuration\n",
    "best_accuracy = 0\n",
    "best_k = None\n",
    "best_metric = None\n",
    "\n",
    "for metric in distance_metrics:\n",
    "    for i, k in enumerate(k_values):\n",
    "        if results[metric][i] > best_accuracy:\n",
    "            best_accuracy = results[metric][i]\n",
    "            best_k = k\n",
    "            best_metric = metric\n",
    "\n",
    "print(f\"\\n*** BEST MODEL: K={best_k}, {best_metric.capitalize()}, Accuracy={best_accuracy:.4f} ({best_accuracy*100:.2f}%) ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Plot: K Values vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#9b59b6', '#f39c12']\n",
    "markers = ['o', 's', '^', 'D', 'p']\n",
    "\n",
    "for idx, metric in enumerate(distance_metrics):\n",
    "    plt.plot(k_values, results[metric], \n",
    "             marker=markers[idx], color=colors[idx],\n",
    "             linewidth=2, markersize=10, label=metric.capitalize())\n",
    "\n",
    "plt.xlabel('K (Number of Neighbors)', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.title('Task 1: K Values vs Accuracy for Different Distance Metrics\\n(Breast Cancer Binary Classification)', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(k_values, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task1_k_vs_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Best Model: Confusion Matrix, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model\n",
    "print(f\"Training best model: K={best_k}, {best_metric.capitalize()}...\")\n",
    "\n",
    "best_knn = KNNClassifier(k=best_k, distance_metric=best_metric)\n",
    "best_knn.fit(X_train, y_train)\n",
    "y_pred_best = best_knn.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "cm, precisions, recalls, acc = EvaluationMetrics.print_classification_report(y_test, y_pred_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "labels = ['B', 'M']\n",
    "cm_ordered, _ = EvaluationMetrics.confusion_matrix(y_test, y_pred_best, labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_ordered, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Benign (B)', 'Malignant (M)'],\n",
    "            yticklabels=['Benign (B)', 'Malignant (M)'],\n",
    "            annot_kws={'size': 16})\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.title(f'Task 1: Confusion Matrix\\n(K={best_k}, {best_metric.capitalize()})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task1_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 BONUS: Decision Boundary Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 2 features by variance for 2D visualization\n",
    "feature_names = df_clean.drop(columns=['diagnosis']).columns.tolist()\n",
    "variances = np.var(X_normalized, axis=0)\n",
    "top_2_features = np.argsort(variances)[-2:]\n",
    "\n",
    "print(f\"Top 2 features for visualization:\")\n",
    "print(f\"  1. {feature_names[top_2_features[0]]}\")\n",
    "print(f\"  2. {feature_names[top_2_features[1]]}\")\n",
    "\n",
    "# Create 2D dataset\n",
    "X_2d = X_normalized[:, top_2_features]\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split_scratch(X_2d, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN on 2D data\n",
    "knn_2d = KNNClassifier(k=best_k, distance_metric=best_metric)\n",
    "knn_2d.fit(X_train_2d, y_train_2d)\n",
    "\n",
    "# Create mesh grid\n",
    "h = 0.02\n",
    "x_min, x_max = X_2d[:, 0].min() - 0.1, X_2d[:, 0].max() + 0.1\n",
    "y_min, y_max = X_2d[:, 1].min() - 0.1, X_2d[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "print(\"Generating decision boundary...\")\n",
    "Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z_numeric = np.array([1 if z == 'M' else 0 for z in Z]).reshape(xx.shape)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundary\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.contourf(xx, yy, Z_numeric, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
    "plt.contour(xx, yy, Z_numeric, colors='k', linewidths=0.5)\n",
    "\n",
    "colors_train = ['#3498db' if l == 'B' else '#e74c3c' for l in y_train_2d]\n",
    "plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=colors_train, \n",
    "           marker='o', s=50, edgecolors='black', linewidth=0.5, alpha=0.7, label='Training')\n",
    "\n",
    "colors_test = ['#3498db' if l == 'B' else '#e74c3c' for l in y_test_2d]\n",
    "plt.scatter(X_test_2d[:, 0], X_test_2d[:, 1], c=colors_test,\n",
    "           marker='s', s=80, edgecolors='black', linewidth=1.5, label='Test')\n",
    "\n",
    "plt.xlabel(feature_names[top_2_features[0]], fontsize=12)\n",
    "plt.ylabel(feature_names[top_2_features[1]], fontsize=12)\n",
    "plt.title(f'Task 1 BONUS: Decision Boundary\\n(K={best_k}, {best_metric.capitalize()})\\nBlue=Benign, Red=Malignant', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task1_decision_boundary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Task 1: Inferences and Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TASK 1: INFERENCES AND OBSERVATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\"\"\n",
    "1. BEST MODEL PERFORMANCE:\n",
    "   - Best K Value: {best_k}\n",
    "   - Best Distance Metric: {best_metric.capitalize()}\n",
    "   - Test Accuracy: {best_accuracy*100:.2f}%\n",
    "\n",
    "2. EFFECT OF K VALUE:\n",
    "   - Smaller K (3, 4): More sensitive to local patterns and noise\n",
    "   - Larger K (20, 47): Smoother boundaries, more robust to noise\n",
    "   - Optimal K balances overfitting and underfitting\n",
    "\n",
    "3. DISTANCE METRIC COMPARISON:\n",
    "   - Euclidean & Manhattan: Perform well on normalized medical data\n",
    "   - Cosine: Good for measuring angular similarity\n",
    "   - Minkowski (p=3): Middle ground between L1 and L2\n",
    "   - Hamming: Less suitable for continuous features\n",
    "\n",
    "4. CLINICAL IMPLICATIONS:\n",
    "   - High precision for Malignant class minimizes false negatives\n",
    "   - Good balance between precision and recall\n",
    "   - KNN provides interpretable predictions based on similar cases\n",
    "\n",
    "5. LIMITATIONS:\n",
    "   - KNN is computationally expensive O(n) per prediction\n",
    "   - Performance depends on feature scaling\n",
    "   - Curse of dimensionality with many features\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 2: Multi-class Classification on CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    \"\"\"Load CIFAR-10 batch file\"\"\"\n",
    "    with open(file, 'rb') as fo:\n",
    "        return pickle.load(fo, encoding='bytes')\n",
    "\n",
    "def load_cifar10(data_dir):\n",
    "    \"\"\"Load CIFAR-10 dataset\"\"\"\n",
    "    cifar_dir = os.path.join(data_dir, 'cifar-10-batches-py')\n",
    "    \n",
    "    # Load training data\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(1, 6):\n",
    "        batch = unpickle(os.path.join(cifar_dir, f'data_batch_{i}'))\n",
    "        X_train.append(batch[b'data'])\n",
    "        y_train.extend(batch[b'labels'])\n",
    "    \n",
    "    X_train = np.vstack(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Load test data\n",
    "    test_batch = unpickle(os.path.join(cifar_dir, 'test_batch'))\n",
    "    X_test = test_batch[b'data']\n",
    "    y_test = np.array(test_batch[b'labels'])\n",
    "    \n",
    "    # Load class names\n",
    "    meta = unpickle(os.path.join(cifar_dir, 'batches.meta'))\n",
    "    class_names = [name.decode('utf-8') for name in meta[b'label_names']]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, class_names\n",
    "\n",
    "# NOTE: Download CIFAR-10 from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "# Extract and place in the same directory\n",
    "print(\"CIFAR-10 loading functions defined!\")\n",
    "print(\"Download link: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 (Update path as needed)\n",
    "data_dir = './'  # Directory containing cifar-10-batches-py folder\n",
    "\n",
    "try:\n",
    "    X_train_cifar, y_train_cifar, X_test_cifar, y_test_cifar, class_names = load_cifar10(data_dir)\n",
    "    print(f\"CIFAR-10 loaded successfully!\")\n",
    "    print(f\"Training: {X_train_cifar.shape[0]} images\")\n",
    "    print(f\"Test: {X_test_cifar.shape[0]} images\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "except:\n",
    "    print(\"Please download CIFAR-10 dataset first!\")\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified sampling for computational efficiency\n",
    "def stratified_sample(X, y, n_per_class=500, random_state=42):\n",
    "    \"\"\"Get stratified sample with n samples per class\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    X_sampled, y_sampled = [], []\n",
    "    \n",
    "    for cls in np.unique(y):\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        sampled = np.random.choice(cls_indices, min(n_per_class, len(cls_indices)), replace=False)\n",
    "        X_sampled.append(X[sampled])\n",
    "        y_sampled.extend([cls] * len(sampled))\n",
    "    \n",
    "    return np.vstack(X_sampled), np.array(y_sampled)\n",
    "\n",
    "# Use subset for efficiency (5000 train, 1000 test)\n",
    "try:\n",
    "    X_train_sample, y_train_sample = stratified_sample(X_train_cifar, y_train_cifar, 500)\n",
    "    X_test_sample, y_test_sample = stratified_sample(X_test_cifar, y_test_cifar, 100)\n",
    "    \n",
    "    # Normalize\n",
    "    X_train_norm = X_train_sample.astype(np.float32) / 255.0\n",
    "    X_test_norm = X_test_sample.astype(np.float32) / 255.0\n",
    "    \n",
    "    print(f\"Sampled: {len(X_train_sample)} train, {len(X_test_sample)} test\")\n",
    "except:\n",
    "    print(\"Using synthetic data for demonstration...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Experiment with Different K Values and Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For computational efficiency, use smaller subsets\n",
    "k_values_cifar = [3, 5, 7, 9, 11]\n",
    "distance_metrics_cifar = ['euclidean', 'manhattan', 'minkowski', 'cosine', 'hamming']\n",
    "results_cifar = {metric: [] for metric in distance_metrics_cifar}\n",
    "\n",
    "print(\"Running CIFAR-10 experiments...\")\n",
    "print(\"(This may take several minutes)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Use smaller subset for faster experiments\n",
    "    X_train_exp, y_train_exp = stratified_sample(X_train_cifar, y_train_cifar, 100)\n",
    "    X_test_exp, y_test_exp = stratified_sample(X_test_cifar, y_test_cifar, 20)\n",
    "    X_train_exp = X_train_exp.astype(np.float32) / 255.0\n",
    "    X_test_exp = X_test_exp.astype(np.float32) / 255.0\n",
    "    \n",
    "    for metric in distance_metrics_cifar:\n",
    "        print(f\"\\nDistance Metric: {metric.upper()}\")\n",
    "        for k in k_values_cifar:\n",
    "            knn = KNNClassifier(k=k, distance_metric=metric)\n",
    "            knn.fit(X_train_exp, y_train_exp)\n",
    "            y_pred = knn.predict(X_test_exp)\n",
    "            accuracy = EvaluationMetrics.accuracy(y_test_exp, y_pred)\n",
    "            results_cifar[metric].append(accuracy)\n",
    "            print(f\"  K={k}: Accuracy = {accuracy:.4f}\")\n",
    "except:\n",
    "    print(\"Please load CIFAR-10 dataset first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Results Summary and Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best configuration\n",
    "best_acc_cifar = 0\n",
    "best_k_cifar = None\n",
    "best_metric_cifar = None\n",
    "\n",
    "for metric in distance_metrics_cifar:\n",
    "    for i, k in enumerate(k_values_cifar):\n",
    "        if results_cifar[metric] and results_cifar[metric][i] > best_acc_cifar:\n",
    "            best_acc_cifar = results_cifar[metric][i]\n",
    "            best_k_cifar = k\n",
    "            best_metric_cifar = metric\n",
    "\n",
    "if best_k_cifar:\n",
    "    print(f\"\\n*** BEST MODEL: K={best_k_cifar}, {best_metric_cifar.capitalize()}, Accuracy={best_acc_cifar:.4f} ***\")\n",
    "    \n",
    "    # Results table\n",
    "    results_cifar_df = pd.DataFrame(results_cifar, index=k_values_cifar)\n",
    "    results_cifar_df.index.name = 'K Value'\n",
    "    print(\"\\nResults Table:\")\n",
    "    print(results_cifar_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Plot: K Values vs Accuracy for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_cifar['euclidean']:  # Check if results exist\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = ['#2ecc71', '#3498db', '#e74c3c', '#9b59b6', '#f39c12']\n",
    "    markers = ['o', 's', '^', 'D', 'p']\n",
    "    \n",
    "    for idx, metric in enumerate(distance_metrics_cifar):\n",
    "        plt.plot(k_values_cifar, results_cifar[metric], \n",
    "                 marker=markers[idx], color=colors[idx],\n",
    "                 linewidth=2, markersize=10, label=metric.capitalize())\n",
    "    \n",
    "    plt.xlabel('K (Number of Neighbors)', fontsize=14)\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.title('Task 2: K Values vs Accuracy for Different Distance Metrics\\n(CIFAR-10 Classification)', fontsize=16)\n",
    "    plt.legend(loc='best', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('task2_k_vs_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Best Model: Confusion Matrix, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_k_cifar:\n",
    "    # Evaluate best model\n",
    "    best_knn_cifar = KNNClassifier(k=best_k_cifar, distance_metric=best_metric_cifar)\n",
    "    best_knn_cifar.fit(X_train_exp, y_train_exp)\n",
    "    y_pred_cifar = best_knn_cifar.predict(X_test_exp)\n",
    "    \n",
    "    # Classification report\n",
    "    cm_cifar, precisions_cifar, recalls_cifar, acc_cifar = EvaluationMetrics.print_classification_report(\n",
    "        y_test_exp, y_pred_cifar, labels=list(range(10)))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm_cifar, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    plt.title(f'Task 2: Confusion Matrix for CIFAR-10\\n(K={best_k_cifar}, {best_metric_cifar.capitalize()})', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('task2_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Task 2: Inferences and Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TASK 2: INFERENCES AND OBSERVATIONS (CIFAR-10)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\"\"\n",
    "1. BEST MODEL PERFORMANCE:\n",
    "   - Best K Value: {best_k_cifar if best_k_cifar else 'N/A'}\n",
    "   - Best Distance Metric: {best_metric_cifar.capitalize() if best_metric_cifar else 'N/A'}\n",
    "   - Test Accuracy: {best_acc_cifar*100:.2f}% (reasonable for KNN on raw pixels)\n",
    "\n",
    "2. CHALLENGES WITH IMAGE DATA:\n",
    "   - CIFAR-10: 32x32x3 = 3072 features per image\n",
    "   - KNN on raw pixels doesn't capture spatial relationships\n",
    "   - Deep learning (CNNs) achieve >95% on CIFAR-10\n",
    "\n",
    "3. DISTANCE METRIC PERFORMANCE:\n",
    "   - Euclidean: Standard choice for continuous pixel values\n",
    "   - Manhattan: Less sensitive to outliers\n",
    "   - Cosine: Measures direction, useful for texture\n",
    "   - Hamming: Poor performance on continuous data\n",
    "\n",
    "4. COMPUTATIONAL CONSIDERATIONS:\n",
    "   - KNN has O(n*d) complexity per prediction\n",
    "   - Used subset of data for practical computation\n",
    "   - PCA or feature extraction recommended for full dataset\n",
    "\n",
    "5. POTENTIAL IMPROVEMENTS:\n",
    "   - Feature extraction (HOG, SIFT, CNN features)\n",
    "   - Dimensionality reduction with PCA\n",
    "   - Weighted KNN for better performance\n",
    "   - Approximate nearest neighbors for speed\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"#\" + \" \"*30 + \"FINAL SUMMARY\" + \" \"*35 + \"#\")\n",
    "print(\"#\"*80)\n",
    "print(f\"\"\"\n",
    "TASK 1: BREAST CANCER BINARY CLASSIFICATION\n",
    "============================================\n",
    "• Dataset: 569 samples, 30 features\n",
    "• Best K: {best_k}\n",
    "• Best Distance: {best_metric.capitalize()}\n",
    "• Accuracy: {best_accuracy*100:.2f}%\n",
    "\n",
    "TASK 2: CIFAR-10 MULTI-CLASS CLASSIFICATION\n",
    "============================================\n",
    "• Dataset: 60,000 images (used subset)\n",
    "• Best K: {best_k_cifar if best_k_cifar else 'N/A'}\n",
    "• Best Distance: {best_metric_cifar.capitalize() if best_metric_cifar else 'N/A'}\n",
    "• Accuracy: {best_acc_cifar*100:.2f}% (baseline for raw pixels)\n",
    "\n",
    "KEY FINDINGS:\n",
    "• Feature normalization is crucial for KNN\n",
    "• Choice of K involves bias-variance tradeoff\n",
    "• Different distance metrics suit different data types\n",
    "• KNN provides interpretable but slow predictions\n",
    "\n",
    "FILES GENERATED:\n",
    "• task1_k_vs_accuracy.png\n",
    "• task1_confusion_matrix.png\n",
    "• task1_decision_boundary.png (BONUS)\n",
    "• task2_k_vs_accuracy.png\n",
    "• task2_confusion_matrix.png\n",
    "\"\"\")\n",
    "print(\"#\"*80)\n",
    "print(\"Assignment completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
